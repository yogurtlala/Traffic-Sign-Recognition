{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc1ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import imutils\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from skimage.feature import hog\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933332d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNS = [\"\",\n",
    "         \"SPEED LIMIT 5\",\n",
    "         \"DO NOT GO STRAIGHT\",\n",
    "         \"DO NOT TURN LEFT\",\n",
    "         \"DO NOT TURN LEFT AND TURN RIGHT\",\n",
    "         \"DO NOT TURN RIGHT\",\n",
    "         \"DO NOT OVERTAKE\",\n",
    "         \"MOTOR VEHICLES ARE PROHIBITED\",\n",
    "         \"DO NOT HONK\",\n",
    "         \"DO NOT PARK\",\n",
    "         \"DO NOT DRIVE IN\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4e3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrastLimit(image): # 输入图像\n",
    "    img_hist_equalized = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb) # YCrCb是BGR颜色空间的一种解码方式\n",
    "    channels = cv2.split(img_hist_equalized) # 拆分图像通道 B/G/R\n",
    "    channels[0] = cv2.equalizeHist(channels[0]) # 直方图均衡化\n",
    "    img_hist_equalized = cv2.merge(channels) # 合并图像通道\n",
    "    img_hist_equalized = cv2.cvtColor(img_hist_equalized, cv2.COLOR_YCrCb2BGR) # 转为BGR格式\n",
    "    return img_hist_equalized # 输出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0109f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaplacianOfGaussian(image): # 输入图像\n",
    "    LoG_image = cv2.GaussianBlur(image, (3,3), 0) # 高斯滤波 减噪\n",
    "    gray = cv2.cvtColor(LoG_image, cv2.COLOR_BGR2GRAY) # 转为灰度图\n",
    "    LoG_image = cv2.Laplacian(gray, cv2.CV_8U,3,3,2) # Laplacian算子 检测边缘\n",
    "    LoG_image = cv2.convertScaleAbs(LoG_image) # 实现将原图片转换为uint8类型\n",
    "    return LoG_image # 输出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9844049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization(image): # 输入图像\n",
    "    thresh = cv2.threshold(image,32,255,cv2.THRESH_BINARY)[1] # 二值化 灰度图像转为二值图像\n",
    "    return thresh # 输出二值图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6b384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image): # 输入图像 预处理\n",
    "    image = constrastLimit(image)\n",
    "    image = LaplacianOfGaussian(image)\n",
    "    image = binarization(image)\n",
    "    return image # 输出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c2fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSmallComponents(image, threshold): # 输入图像和阈值\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8) # 查找所有连接的部分\n",
    "    # 返回值： nb_components 连通区域数量 output 与image大小相同的矩形 每一个连通区域有一个唯一标识\n",
    "    # stats 包含五个参数x y h w s，分别对应每一个连通区域的外接矩形的起始坐标\n",
    "    # centroids 连通区域的质心\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "    img2 = np.zeros((output.shape),dtype = np.uint8)\n",
    "    \n",
    "    for i in range(0, nb_components): # 对于每个部分 仅当高于阈值才保留\n",
    "        if sizes[i] >= threshold:\n",
    "            img2[output == i + 1] = 255\n",
    "    return img2 # 输出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05c9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findContour(image): # 输入图像\n",
    "    cnts, h = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # 查找轮廓\n",
    "    return cnts # 返回list list中的每一个元素都是一个轮廓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53ce535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contourIsSign(perimeter, centroid, threshold): # 参数：周长 圆心 阈值\n",
    "    result = []\n",
    "    for p in perimeter: # 算出每个点离质心的距离 存入result\n",
    "        p = p[0]\n",
    "        distance = sqrt((p[0] - centroid[0])**2 + (p[1] - centroid[1])**2)\n",
    "        result.append(distance)\n",
    "        \n",
    "    max_value = max(result) # 找到最大距离\n",
    "    signature = [float(dist) / max_value for dist in result ] # \n",
    "    temp = sum((1 - s) for s in signature)\n",
    "    temp = temp / len(signature)\n",
    "    \n",
    "    if temp < threshold: \n",
    "        return True, max_value + 2\n",
    "    else:                \n",
    "        return False, max_value + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae82b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropSign(image, coordinate): # 输入图像 坐标\n",
    "    width = image.shape[1] # 宽\n",
    "    height = image.shape[0] # 高\n",
    "    top = max([int(coordinate[0][1]), 0])\n",
    "    bottom = min([int(coordinate[1][1]), height-1])\n",
    "    left = max([int(coordinate[0][0]), 0])\n",
    "    right = min([int(coordinate[1][0]), width-1])\n",
    "    return image[top:bottom,left:right] # 裁剪 输出裁剪后的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0dc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLargestSign(image, contours, threshold, distance_theshold): # 输入图像 轮廓 阈值 距离阈值\n",
    "    max_distance = 0\n",
    "    coordinate = None\n",
    "    sign = None\n",
    "    for c in contours: # 遍历轮廓\n",
    "        M = cv2.moments(c)\n",
    "        if cv2.contourArea(c) == 0:\n",
    "            continue\n",
    "#         if M[\"m00\"] == 0:\n",
    "#             continue\n",
    "        # M[\"m00\"]表示轮廓面积 \n",
    "        cX = int(M[\"m10\"] / M[\"m00\"]) # 质心 x\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"]) # 质心 y\n",
    "        is_sign, distance = contourIsSign(c, [cX, cY], 1-threshold)\n",
    "        if is_sign and distance > max_distance and distance > distance_theshold:\n",
    "            max_distance = distance # 更新最大距离\n",
    "            coordinate = np.reshape(c, [-1,2])\n",
    "            left, top = np.amin(coordinate, axis=0)\n",
    "            right, bottom = np.amax(coordinate, axis = 0)\n",
    "            coordinate = [(left-2,top-2),(right+3,bottom+1)]\n",
    "            sign = cropSign(image,coordinate)\n",
    "    return sign, coordinate # 返回裁剪过后的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7ec010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_other_color(img):\n",
    "    frame = cv2.GaussianBlur(img, (3,3), 0) \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([100,128,0]) # 蓝色\n",
    "    upper_blue = np.array([215,255,255])\n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    lower_white = np.array([0,0,128], dtype=np.uint8)\n",
    "    upper_white = np.array([255,255,255], dtype=np.uint8)\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    lower_black = np.array([0,0,0], dtype=np.uint8)\n",
    "    upper_black = np.array([170,150,50], dtype=np.uint8)\n",
    "    mask_black = cv2.inRange(hsv, lower_black, upper_black)\n",
    "    mask_1 = cv2.bitwise_or(mask_blue, mask_white)\n",
    "    mask = cv2.bitwise_or(mask_1, mask_black)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0f7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization(image, current_sign_type):\n",
    "    original_image = image.copy()\n",
    "    binary_image = preprocess_image(image)\n",
    "    binary_image = removeSmallComponents(binary_image, 300)\n",
    "    binary_image = cv2.bitwise_and(binary_image,binary_image, mask=remove_other_color(image))\n",
    "    contours = findContour(binary_image)\n",
    "    sign, coordinate = findLargestSign(original_image, contours, 0.65, 15)\n",
    "    \n",
    "    text = \"\"\n",
    "    sign_type = -1\n",
    "    i = 0\n",
    "    new_model = joblib.load(\"my_model_SVM.m\")\n",
    "    \n",
    "    if sign is not None:\n",
    "        sign = cv2.cvtColor(sign, cv2.COLOR_BGR2GRAY) \n",
    "        sign = transform.resize(sign, (128, 128))\n",
    "        feature = hog(sign, orientations=8, pixels_per_cell=(10, 10),\n",
    "                cells_per_block=(1, 1), visualize=False, channel_axis=None)\n",
    "        feature = feature.reshape(1, -1)\n",
    "        y_pred = new_model.predict(feature)\n",
    "        y_pred = y_pred[0]\n",
    "        sign_type = y_pred\n",
    "        text = SIGNS[sign_type]\n",
    "    return coordinate, original_image, sign_type, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c38606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    vidcap = cv2.VideoCapture('C:\\\\Users\\\\lenovo\\\\Desktop\\\\video1.mp4') # 视频文件\n",
    "    # vidcap = cv2.VideoCapture(0) # 实时检测\n",
    "\n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "    roiBox = None\n",
    "    roiHist = None\n",
    "    success = True\n",
    "    count = 0\n",
    "    current_sign = None\n",
    "    current_text = \"\"\n",
    "    current_size = 0\n",
    "    sign_count = 0\n",
    "    coordinates = []\n",
    "    position = []\n",
    "\n",
    "    while True:\n",
    "        success,frame = vidcap.read() # 按帧读取视频\n",
    "        # 第一个返回值为布尔值 正确读取为True 读到结尾为False 第二个返回值为每一帧的图像/三维矩阵\n",
    "        if not success: # 如果读到视频结尾\n",
    "            print(\"FINISHED\") # 输出FINISHED\n",
    "            break # 跳出循环\n",
    "\n",
    "        print(\"Frame:{}\".format(count)) # 第几帧\n",
    "        coordinate, image, sign_type, text = localization(frame, current_sign)\n",
    "\n",
    "        if sign_type > 0 and (not current_sign or sign_type != current_sign):\n",
    "            current_sign = sign_type # 更新当前sign_type\n",
    "            current_text = text\n",
    "            top = int(coordinate[0][1]*1.05)\n",
    "            left = int(coordinate[0][0]*1.05)\n",
    "            bottom = int(coordinate[1][1]*0.95)\n",
    "            right = int(coordinate[1][0]*0.95)\n",
    "\n",
    "            # 显示图片\n",
    "            cv2.rectangle(image, coordinate[0],coordinate[1], (245,255,0), 5) #\n",
    "            font = cv2.FONT_HERSHEY_PLAIN\n",
    "            cv2.putText(image,text,(coordinate[0][0], coordinate[0][1] -15), font, 2,(245,255,0),2,cv2.LINE_4)\n",
    "\n",
    "            tl = [left, top]\n",
    "            br = [right,bottom]\n",
    "            current_size = math.sqrt(math.pow((tl[0]-br[0]),2) + math.pow((tl[1]-br[1]),2)) # 对角线长\n",
    "\n",
    "            roi = frame[tl[1]:br[1], tl[0]:br[0]] # 裁剪下的图片\n",
    "            if np.size(roi) == 0:\n",
    "                roi = image\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV) # HSV\n",
    "\n",
    "\n",
    "            roiHist = cv2.calcHist([roi], [0], None, [16], [0, 180]) # 直方图\n",
    "            roiHist = cv2.normalize(roiHist, roiHist, 0, 255, cv2.NORM_MINMAX) # 规范化\n",
    "            roiBox = (tl[0], tl[1], br[0], br[1])\n",
    "\n",
    "        elif current_sign:\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            backProj = cv2.calcBackProject([hsv], [0], roiHist, [0, 180], 1) # 反向投影\n",
    "            (r, roiBox) = cv2.CamShift(backProj, roiBox, termination) # 目标跟踪\n",
    "            pts = np.int0(cv2.boxPoints(r))\n",
    "            s = pts.sum(axis = 1)\n",
    "            tl = pts[np.argmin(s)]\n",
    "            br = pts[np.argmax(s)]\n",
    "            size = math.sqrt(pow((tl[0]-br[0]),2) + pow((tl[1]-br[1]),2))\n",
    "\n",
    "            if  current_size < 1 or size < 1 or size / current_size > 30 or math.fabs((tl[0]-br[0])/(tl[1]-br[1])) > 2 or math.fabs((tl[0]-br[0])/(tl[1]-br[1])) < 0.5:\n",
    "                current_sign = None\n",
    "                print(\"Stop tracking\")\n",
    "            else:\n",
    "                current_size = size\n",
    "\n",
    "            if sign_type > 0:\n",
    "                top = int(coordinate[0][1])\n",
    "                left = int(coordinate[0][0])\n",
    "                bottom = int(coordinate[1][1])\n",
    "                right = int(coordinate[1][0])\n",
    "\n",
    "                cv2.rectangle(image, coordinate[0],coordinate[1], (245,255,0), 5)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                cv2.putText(image,text,(coordinate[0][0], coordinate[0][1] -15), font, 2,(245,255,0),2,cv2.LINE_4)\n",
    "\n",
    "            elif current_sign:\n",
    "                cv2.rectangle(image, (tl[0], tl[1]),(br[0], br[1]), (245,255,0), 5)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                cv2.putText(image,current_text,(tl[0], tl[1] -15), font, 2,(245,255,0),2,cv2.LINE_4)\n",
    "\n",
    "        cv2.imshow('Result', image)\n",
    "        count = count + 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    print(\"Finish {} frames\".format(count))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a02674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:0\n",
      "Frame:1\n",
      "Frame:2\n",
      "Frame:3\n",
      "Frame:4\n",
      "Stop tracking\n",
      "Frame:5\n",
      "Frame:6\n",
      "Frame:7\n",
      "Frame:8\n",
      "Stop tracking\n",
      "Frame:9\n",
      "Frame:10\n",
      "Frame:11\n",
      "Frame:12\n",
      "Stop tracking\n",
      "Frame:13\n",
      "Frame:14\n",
      "Frame:15\n",
      "Frame:16\n",
      "Stop tracking\n",
      "Frame:17\n",
      "Frame:18\n",
      "Frame:19\n",
      "Frame:20\n",
      "Stop tracking\n",
      "Frame:21\n",
      "Frame:22\n",
      "Frame:23\n",
      "Frame:24\n",
      "Stop tracking\n",
      "Frame:25\n",
      "Frame:26\n",
      "Frame:27\n",
      "Frame:28\n",
      "Stop tracking\n",
      "Frame:29\n",
      "Frame:30\n",
      "Frame:31\n",
      "Frame:32\n",
      "Frame:33\n",
      "Frame:34\n",
      "Stop tracking\n",
      "Frame:35\n",
      "Frame:36\n",
      "Frame:37\n",
      "Stop tracking\n",
      "Frame:38\n",
      "Frame:39\n",
      "Stop tracking\n",
      "Frame:40\n",
      "Frame:41\n",
      "Stop tracking\n",
      "Frame:42\n",
      "Frame:43\n",
      "Stop tracking\n",
      "Frame:44\n",
      "Frame:45\n",
      "Stop tracking\n",
      "Frame:46\n",
      "Frame:47\n",
      "Stop tracking\n",
      "Frame:48\n",
      "Frame:49\n",
      "Stop tracking\n",
      "Frame:50\n",
      "Frame:51\n",
      "Stop tracking\n",
      "Frame:52\n",
      "Frame:53\n",
      "Stop tracking\n",
      "Frame:54\n",
      "Frame:55\n",
      "Stop tracking\n",
      "Frame:56\n",
      "Frame:57\n",
      "Stop tracking\n",
      "Frame:58\n",
      "Frame:59\n",
      "Stop tracking\n",
      "Frame:60\n",
      "Frame:61\n",
      "Stop tracking\n",
      "Frame:62\n",
      "Frame:63\n",
      "Stop tracking\n",
      "Frame:64\n",
      "Frame:65\n",
      "Stop tracking\n",
      "Frame:66\n",
      "Frame:67\n",
      "Stop tracking\n",
      "Frame:68\n",
      "Frame:69\n",
      "Stop tracking\n",
      "Frame:70\n",
      "Frame:71\n",
      "Stop tracking\n",
      "Frame:72\n",
      "Frame:73\n",
      "Stop tracking\n",
      "Frame:74\n",
      "Frame:75\n",
      "Stop tracking\n",
      "Frame:76\n",
      "Frame:77\n",
      "Stop tracking\n",
      "Frame:78\n",
      "Frame:79\n",
      "Stop tracking\n",
      "Frame:80\n",
      "Frame:81\n",
      "Stop tracking\n",
      "Frame:82\n",
      "Frame:83\n",
      "Stop tracking\n",
      "Frame:84\n",
      "Frame:85\n",
      "Stop tracking\n",
      "Frame:86\n",
      "Frame:87\n",
      "Stop tracking\n",
      "Frame:88\n",
      "Frame:89\n",
      "Stop tracking\n",
      "Frame:90\n",
      "Frame:91\n",
      "Frame:92\n",
      "Frame:93\n",
      "Frame:94\n",
      "Stop tracking\n",
      "Frame:95\n",
      "Frame:96\n",
      "Frame:97\n",
      "Stop tracking\n",
      "Frame:98\n",
      "Frame:99\n",
      "Frame:100\n",
      "Stop tracking\n",
      "Frame:101\n",
      "Frame:102\n",
      "Frame:103\n",
      "Stop tracking\n",
      "Frame:104\n",
      "Frame:105\n",
      "Frame:106\n",
      "Frame:107\n",
      "Stop tracking\n",
      "Frame:108\n",
      "Frame:109\n",
      "Frame:110\n",
      "Frame:111\n",
      "Stop tracking\n",
      "Frame:112\n",
      "Frame:113\n",
      "Frame:114\n",
      "Frame:115\n",
      "Stop tracking\n",
      "Frame:116\n",
      "Frame:117\n",
      "Frame:118\n",
      "Frame:119\n",
      "Frame:120\n",
      "Stop tracking\n",
      "Frame:121\n",
      "Frame:122\n",
      "Frame:123\n",
      "Stop tracking\n",
      "Frame:124\n",
      "Frame:125\n",
      "Frame:126\n",
      "Stop tracking\n",
      "Frame:127\n",
      "Frame:128\n",
      "Frame:129\n",
      "Stop tracking\n",
      "Frame:130\n",
      "Frame:131\n",
      "Frame:132\n",
      "Stop tracking\n",
      "Frame:133\n",
      "Frame:134\n",
      "Frame:135\n",
      "Stop tracking\n",
      "Frame:136\n",
      "Frame:137\n",
      "Frame:138\n",
      "Stop tracking\n",
      "Frame:139\n",
      "Frame:140\n",
      "Frame:141\n",
      "Frame:142\n",
      "Frame:143\n",
      "Frame:144\n",
      "Frame:145\n",
      "Frame:146\n",
      "Frame:147\n",
      "Frame:148\n",
      "Frame:149\n",
      "Frame:150\n",
      "Frame:151\n",
      "Frame:152\n",
      "Frame:153\n",
      "Frame:154\n",
      "Stop tracking\n",
      "Frame:155\n",
      "Frame:156\n",
      "Frame:157\n",
      "Frame:158\n",
      "Frame:159\n",
      "Frame:160\n",
      "Frame:161\n",
      "Frame:162\n",
      "Frame:163\n",
      "Frame:164\n",
      "Frame:165\n",
      "Frame:166\n",
      "Frame:167\n",
      "Frame:168\n",
      "Frame:169\n",
      "Frame:170\n",
      "Frame:171\n",
      "Frame:172\n",
      "Frame:173\n",
      "Frame:174\n",
      "Frame:175\n",
      "Frame:176\n",
      "Frame:177\n",
      "Frame:178\n",
      "Frame:179\n",
      "Frame:180\n",
      "Frame:181\n",
      "Frame:182\n",
      "Frame:183\n",
      "Frame:184\n",
      "Frame:185\n",
      "Frame:186\n",
      "Frame:187\n",
      "Frame:188\n",
      "Frame:189\n",
      "Frame:190\n",
      "Frame:191\n",
      "Frame:192\n",
      "Stop tracking\n",
      "Frame:193\n",
      "Frame:194\n",
      "Frame:195\n",
      "Stop tracking\n",
      "Frame:196\n",
      "Frame:197\n",
      "Stop tracking\n",
      "Frame:198\n",
      "Frame:199\n",
      "Stop tracking\n",
      "Frame:200\n",
      "Frame:201\n",
      "Stop tracking\n",
      "Frame:202\n",
      "Frame:203\n",
      "Stop tracking\n",
      "Frame:204\n",
      "Frame:205\n",
      "Frame:206\n",
      "Frame:207\n",
      "Frame:208\n",
      "Frame:209\n",
      "Frame:210\n",
      "Frame:211\n",
      "Frame:212\n",
      "Frame:213\n",
      "Frame:214\n",
      "Frame:215\n",
      "Frame:216\n",
      "Frame:217\n",
      "Frame:218\n",
      "Frame:219\n",
      "Frame:220\n",
      "Frame:221\n",
      "Frame:222\n",
      "Frame:223\n",
      "Frame:224\n",
      "Frame:225\n",
      "Frame:226\n",
      "Frame:227\n",
      "Frame:228\n",
      "Frame:229\n",
      "Frame:230\n",
      "Frame:231\n",
      "Frame:232\n",
      "Frame:233\n",
      "Frame:234\n",
      "Frame:235\n",
      "Frame:236\n",
      "Frame:237\n",
      "Frame:238\n",
      "Frame:239\n",
      "Frame:240\n",
      "Stop tracking\n",
      "FINISHED\n",
      "Finish 241 frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74328ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
